{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancePS(centerSet: np.ndarray, i: int, complete: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Returns the distance between a certain point and a certain set.\n",
    "    \n",
    "    Parameters:\n",
    "        centerSet: A numpy array containing confirmed center indexes\n",
    "        i: The index of any point\n",
    "        complete : Complete graph adjacency matrix containing distances between all pairs of points\n",
    "    \n",
    "    Returns:\n",
    "        min_distance: The distance between point and center set\n",
    "    \"\"\"\n",
    "    min_distance = float(\"inf\")\n",
    "    for center in centerSet:\n",
    "        distance = complete[center][i]\n",
    "        if (distance < min_distance):\n",
    "            min_distance = distance\n",
    "    \n",
    "    return min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM(points_index: np.ndarray, k: int, complete: np.ndarray, initial: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns indexes of k centers after running GMM Algorithm.\n",
    "    \n",
    "    Parameters: \n",
    "        points_index: The indexes of data\n",
    "        k: A decimal integer, the number of centers\n",
    "        complete: Complete graph adjacency matrix containing distances between all pairs of points\n",
    "        initial: An initial set of elements\n",
    "    \n",
    "    Returns:\n",
    "        centers: A numpy array with k indexes as center point indexes\n",
    "    \"\"\"\n",
    "    centers = []\n",
    "    initial_list = list(initial)\n",
    "    if len(initial) == 0:\n",
    "        initial_point_index = random.choice(points_index)\n",
    "        centers.append(initial_point_index)\n",
    "    while (len(centers) < k):\n",
    "        max_distance = 0\n",
    "        max_distance_vector_index = None\n",
    "        for i in points_index:\n",
    "            distance = distancePS(centers + initial_list, i, complete)\n",
    "            if distance > max_distance:\n",
    "                max_distance = distance\n",
    "                max_distance_vector_index = i\n",
    "        centers.append(max_distance_vector_index)\n",
    "    centers = np.array(centers)\n",
    "\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FairSwap(complete: np.ndarray, set_1: np.ndarray, set_2: np.ndarray, k_1: int, k_2: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Performs max-min fair diversification under partition matroid constraint when m = 2.\n",
    "    From the paper Diverse Data Selection under Fairness Constraints\n",
    "\n",
    "    Parameters:\n",
    "        complete: Complete graph adjacency matrix containing distances between all pairs of points\n",
    "        set_1: First set of points\n",
    "        set_2: Second set of points \n",
    "        k_1: Number of points to select from set_1\n",
    "        k_2: Number of points to select from set_2\n",
    "        \n",
    "    Returns:\n",
    "        final_centers_u: \n",
    "        final_centers_o: \n",
    "    \"\"\"\n",
    "    amount = complete.shape[0]\n",
    "    complete_array = np.arange(amount)\n",
    "    centers = GMM(complete_array, k_1 + k_2, complete, np.empty(0))\n",
    "    centers_1 = np.intersect1d(centers, set_1)\n",
    "    centers_2 = np.intersect1d(centers, set_2)\n",
    "    \n",
    "    number_1 = k_1 - len(centers_1)\n",
    "    number_2 = k_2 - len(centers_2)\n",
    "    centers_u = None\n",
    "    centers_o = None\n",
    "    set_u = None\n",
    "    set_o = None\n",
    "    number_u = None\n",
    "    number_o = None\n",
    "    centers_u, centers_o, set_u, set_o, number_u, number_o = (\n",
    "    (centers_1, centers_2, set_1, set_2, number_1, number_2) \n",
    "    if number_1 < number_2 \n",
    "    else (centers_2, centers_1, set_2, set_1, number_2, number_1)\n",
    "    )\n",
    "\n",
    "    points_e = GMM(set_u, number_u, complete, centers_u)\n",
    "\n",
    "    points_r = []\n",
    "    for point in points_e:\n",
    "        min_distance = float(\"inf\")\n",
    "        r = None\n",
    "        for o in centers_o: \n",
    "            distance = complete[point][o]\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                r = o\n",
    "        points_r.append(r)\n",
    "    points_r = np.array(points_r)\n",
    "    \n",
    "    final_centers_u = np.union1d(centers_u, points_e)\n",
    "    final_centers_o = np.setdiff1d(centers_o, points_r)\n",
    "\n",
    "    return final_centers_u, final_centers_o\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FairFlow(complete: np.ndarray, sets: tuple, gamma: float):\n",
    "    \"\"\"\n",
    "    Performs max-min fair diversification under partition matroid constraint when m > 2.\n",
    "    From the paper Diverse Data Selection under Fairness Constraints\n",
    "\n",
    "    Parameters:\n",
    "        complete: Complete graph adjacency matrix containing distances between all pairs of points\n",
    "        set_s: The points including critical regions and k\n",
    "        gamma: A guess of the optimum fair diversity\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    # 获取集合数量m和每个集合对应的k值\n",
    "    m = len(sets)\n",
    "    ks = [s[1] for s in sets]\n",
    "    universes = [s[0] for s in sets]\n",
    "    \n",
    "    # 步骤1-3: 对每个集合使用GMM算法\n",
    "    Y = []\n",
    "    for i in range(m):\n",
    "        y_i = GMM(universes[i], ks[i], complete, np.array([]))\n",
    "        Y.append(y_i)\n",
    "        \n",
    "    # 步骤4: 计算Z_i\n",
    "    d1 = m / (3*m-1) * gamma\n",
    "    Z = []\n",
    "    for i in range(m):\n",
    "        z_i = []\n",
    "        for y in Y[i]:\n",
    "            valid = True\n",
    "            for z in z_i:\n",
    "                if complete[y][z] < d1:\n",
    "                    valid = False\n",
    "                    break\n",
    "            if valid:\n",
    "                z_i.append(y)\n",
    "        Z.append(np.array(z_i))\n",
    "    \n",
    "    # 步骤5-6: 构建无向图G_Z并获取连通分量\n",
    "    d2 = 2/(3*m-1) * gamma\n",
    "    nodes = np.concatenate(Z)\n",
    "    edges = []\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            if complete[nodes[i]][nodes[j]] <= d2:\n",
    "                edges.append((nodes[i], nodes[j]))\n",
    "                \n",
    "    # 使用并查集找到连通分量\n",
    "    parent = {node: node for node in nodes}\n",
    "    def find(x):\n",
    "        if parent[x] != x:\n",
    "            parent[x] = find(parent[x])\n",
    "        return parent[x]\n",
    "    \n",
    "    def union(x, y):\n",
    "        parent[find(x)] = find(y)\n",
    "        \n",
    "    for edge in edges:\n",
    "        union(edge[0], edge[1])\n",
    "        \n",
    "    components = {}\n",
    "    for node in nodes:\n",
    "        root = find(node)\n",
    "        if root not in components:\n",
    "            components[root] = []\n",
    "        components[root].append(node)\n",
    "    \n",
    "    C = list(components.values())\n",
    "    \n",
    "    # 步骤7-8: 构建有向图并计算最大流\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    def max_flow(graph, source, sink):\n",
    "        def bfs(graph, source, sink, parent):\n",
    "            visited = set()\n",
    "            queue = [source]\n",
    "            visited.add(source)\n",
    "            while queue:\n",
    "                u = queue.pop(0)\n",
    "                for v, cap in graph[u].items():\n",
    "                    if v not in visited and cap > 0:\n",
    "                        queue.append(v)\n",
    "                        visited.add(v)\n",
    "                        parent[v] = u\n",
    "            return sink in visited\n",
    "            \n",
    "        flow = 0\n",
    "        parent = {}\n",
    "        while bfs(graph, source, sink, parent):\n",
    "            path_flow = float(\"inf\")\n",
    "            s = sink\n",
    "            while s != source:\n",
    "                path_flow = min(path_flow, graph[parent[s]][s])\n",
    "                s = parent[s]\n",
    "            flow += path_flow\n",
    "            v = sink\n",
    "            while v != source:\n",
    "                u = parent[v]\n",
    "                graph[u][v] -= path_flow\n",
    "                graph[v][u] += path_flow\n",
    "                v = parent[v]\n",
    "        return flow\n",
    "    \n",
    "    # 构建网络流图\n",
    "    graph = defaultdict(lambda: defaultdict(int))\n",
    "    source = 'source'\n",
    "    sink = 'sink'\n",
    "    \n",
    "    # 添加从源点到u_i的边\n",
    "    for i in range(m):\n",
    "        graph[source][f'u_{i}'] = ks[i]\n",
    "    \n",
    "    # 添加从u_i到v_j的边\n",
    "    for i in range(m):\n",
    "        for j, comp in enumerate(C):\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coresets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
